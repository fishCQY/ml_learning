DenseNet-121是一种高效的卷积神经网络，其名称中的“121”代表网络包含约121层可训练参数层。它的核心设计思想是通过**密集连接（Dense Connectivity）**和**密集块（Dense Block）**实现特征的高效复用。以下是DenseNet-121的详细计算过程：

![img](https://cdn.jsdelivr.net/gh/jessieyyyy/Imgpicgo/Img/densenet-tab-1-dnet121.jpg)

------

### 一、整体结构

DenseNet-121由以下部分组成：

1. **初始卷积层**：快速下采样。
2. **4个Dense Block**：每个块包含多个密集连接的层。
3. **3个Transition Layer**：连接相邻Dense Block，用于压缩通道和下采样。
4. **全局平均池化 + 全连接层**：输出分类结果。

整体结构如下（简化为4个Dense Block和3个Transition Layer）：

```
Input → Conv7x7 → MaxPool → DenseBlock1 → Transition1 → DenseBlock2 → Transition2 → DenseBlock3 → Transition3 → DenseBlock4 → GlobalAvgPool → FC → Output
```

------

### 二、详细计算步骤（以输入`224x224x3`为例）

#### **1. 初始卷积层**

- **操作**：7x7卷积 + 步长2 + 填充3
- **输入**：`224x224x3`
- **输出**：`112x112x64`
- **公式**：尺寸=2224+2×3−7+1=112

#### **2. 最大池化**

- **操作**：3x3池化 + 步长2 + 填充1
- **输入**：`112x112x64`
- **输出**：`56x56x64`
- **公式**：尺寸=2112+2×1−3+1=56

------

#### **3. Dense Block 1**

- 结构：6个Dense Layer，每个Layer包含：
  1. **BN-ReLU-1x1 Conv（Bottleneck）**：减少通道数到`4k = 128`。
  2. **BN-ReLU-3x3 Conv**：输出增长率为`k=32`通道。
- **输入通道**初始为64，每层新增32通道，最终输出通道数为：64+6×32=256
- **输入维度**：`56x56x64 → 56x56x256`

------

#### **4. Transition Layer 1**

- 操作：
  - **1x1卷积**：压缩通道数为`256×0.5=128`。
  - **2x2平均池化**：下采样到`28x28`。
- **输入**：`56x56x256 → Transition → 28x28x128`

------

#### **5. Dense Block 2**

- **结构**：12个Dense Layer，增长率为`k=32`。
- **输入通道**：128，最终输出通道：128+12×32=512
- **输出维度**：`28x28x512`

------

#### **6. Transition Layer 2**

- **1x1卷积**：通道压缩到`512×0.5=256`。
- **池化**：尺寸减半到`14x14`。
- **输出**：`14x14x256`

------

#### **7. Dense Block 3**

- **结构**：24个Dense Layer，增长率`k=32`。
- **输入通道**：256，最终输出通道：256+24×32=1024
- **输出维度**：`14x14x1024`

------

#### **8. Transition Layer 3**

- **1x1卷积**：通道压缩到`1024×0.5=512`。
- **池化**：尺寸减半到`7x7`。
- **输出**：`7x7x512`

------

#### **9. Dense Block 4**

- **结构**：16个Dense Layer，增长率`k=32`。
- **输入通道**：512，最终输出通道：512+16×32=1024
- **输出维度**：`7x7x1024`

------

#### **10. 全局平均池化**

- **操作**：将`7x7x1024`平均池化为`1x1x1024`。
- **输出**：`1024维特征向量`。

------

#### **11. 全连接层**

- **输入**：1024维特征向量。
- **输出**：1000维分类结果（ImageNet类别数）。
- **公式**：Output=Softmax(*W*⋅*x*+*b*)

------

### 三、关键计算特点

1. **密集连接**：
   - 每个Dense Layer的输入是前面所有层输出通道的拼接。
   - **特征复用示例**：
     假设Dense Block1的第3层输入为：Input=[Layer1输出,Layer2输出](通道拼接)
2. **参数效率**：
   - Growth Rate（`k=32`）控制新增通道数。
   - 1x1的Bottleneck卷积（减少通道到`4k`）降低计算量。

------

### 四、参数数量示例

以Dense Block1的某Dense Layer为例：

- **输入通道**：64（初始）→ 每层+32通道。
- 操作：
  1. 1x1卷积将输入通道到`4k=128`。
  2. 3x3卷积生成`k=32`通道。
- **参数量**：1×1×64×128+3×3×128×32=8192+36,864=45,056参数



------

### 总结

DenseNet-121通过密集连接和Bottleneck设计，在保持参数效率的同时实现了深度特征的学习。每个Dense Block内的特征拼接和多层Bottleneck计算是其高效性的核心。该网络在ImageNet上Top-1准确率约75%，参数量仅约8百万，远小于VGG-16（1.38亿）、ResNet-50（2.5千万）。